{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['002.Laysan_Albatross',\n",
       " '012.Yellow_headed_Blackbird',\n",
       " '014.Indigo_Bunting',\n",
       " '025.Pelagic_Cormorant',\n",
       " '029.American_Crow',\n",
       " '033.Yellow_billed_Cuckoo',\n",
       " '035.Purple_Finch',\n",
       " '042.Vermilion_Flycatcher',\n",
       " '048.European_Goldfinch',\n",
       " '050.Eared_Grebe',\n",
       " '059.California_Gull',\n",
       " '068.Ruby_throated_Hummingbird',\n",
       " '073.Blue_Jay',\n",
       " '081.Pied_Kingfisher',\n",
       " '095.Baltimore_Oriole',\n",
       " '101.White_Pelican',\n",
       " '106.Horned_Puffin',\n",
       " '108.White_necked_Raven',\n",
       " '112.Great_Grey_Shrike',\n",
       " '118.House_Sparrow',\n",
       " '134.Cape_Glossy_Starling',\n",
       " '138.Tree_Swallow',\n",
       " '144.Common_Tern',\n",
       " '191.Red_headed_Woodpecker']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PATH_TO_RINS = \"/home/strazi\" # REPLACE WITH YOUR PATH!!!\n",
    "\n",
    "with open(f\"{PATH_TO_RINS}/RINS-kappa/workspace/src/task_2s/data/relevant_species.txt\") as f:\n",
    "    relevant_species = f.read().splitlines()\n",
    "\n",
    "relevant_species = [s.strip() for s in relevant_species if s.strip()]\n",
    "relevant_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    image_id                                         image_name  class_id  \\\n",
      "60        61  002.Laysan_Albatross/Laysan_Albatross_0002_102...         2   \n",
      "61        62  002.Laysan_Albatross/Laysan_Albatross_0003_103...         2   \n",
      "62        63  002.Laysan_Albatross/Laysan_Albatross_0082_524...         2   \n",
      "63        64  002.Laysan_Albatross/Laysan_Albatross_0044_784...         2   \n",
      "64        65  002.Laysan_Albatross/Laysan_Albatross_0070_788...         2   \n",
      "\n",
      "              class_name  is_training_image  bbox_x  bbox_y  bbox_width  \\\n",
      "60  002.Laysan_Albatross                  0   144.0    40.0       333.0   \n",
      "61  002.Laysan_Albatross                  1   202.0    28.0       164.0   \n",
      "62  002.Laysan_Albatross                  0    72.0    68.0       383.0   \n",
      "63  002.Laysan_Albatross                  1    60.0   128.0       438.0   \n",
      "64  002.Laysan_Albatross                  0    32.0    35.0       259.0   \n",
      "\n",
      "    bbox_height                                         image_path  \n",
      "60        165.0  /home/strazi/RINS-kappa/workspace/src/task_2s/...  \n",
      "61        340.0  /home/strazi/RINS-kappa/workspace/src/task_2s/...  \n",
      "62        225.0  /home/strazi/RINS-kappa/workspace/src/task_2s/...  \n",
      "63        106.0  /home/strazi/RINS-kappa/workspace/src/task_2s/...  \n",
      "64        361.0  /home/strazi/RINS-kappa/workspace/src/task_2s/...  \n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "root_dir = f'{PATH_TO_RINS}/RINS-kappa/workspace/src/task_2s/data/CUB_200_2011/CUB_200_2011'\n",
    "images_txt = f'{root_dir}/images.txt'\n",
    "image_class_labels_txt = f'{root_dir}/image_class_labels.txt'\n",
    "classes_txt = f'{root_dir}/classes.txt'\n",
    "train_test_split_txt = f'{root_dir}/train_test_split.txt'\n",
    "bounding_boxes_txt = f'{root_dir}/bounding_boxes.txt'\n",
    "\n",
    "# Load files\n",
    "images_df = pd.read_csv(images_txt, sep=' ', names=['image_id', 'image_name'])\n",
    "labels_df = pd.read_csv(image_class_labels_txt, sep=' ', names=['image_id', 'class_id'])\n",
    "classes_df = pd.read_csv(classes_txt, sep=' ', names=['class_id', 'class_name'])\n",
    "split_df = pd.read_csv(train_test_split_txt, sep=' ', names=['image_id', 'is_training_image'])\n",
    "bboxes_df = pd.read_csv(bounding_boxes_txt, sep=' ', names=['image_id', 'bbox_x', 'bbox_y', 'bbox_width', 'bbox_height'])\n",
    "\n",
    "# Merge all together\n",
    "df = images_df.merge(labels_df, on='image_id') \\\n",
    "              .merge(classes_df, on='class_id') \\\n",
    "              .merge(split_df, on='image_id') \\\n",
    "              .merge(bboxes_df, on='image_id')\n",
    "\n",
    "# Add full image path (optional)\n",
    "df['image_path'] = root_dir + '/images/' + df['image_name']\n",
    "\n",
    "# Filter for relevant species\n",
    "df = df[df['class_name'].isin(relevant_species)]\n",
    "\n",
    "# Show the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/strazi/RINS-kappa/workspace/src/task_2s/models/label_encoder.pkl']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['class_name'])\n",
    "num_classes = len(le.classes_)\n",
    "print(f'{num_classes} classes')\n",
    "joblib.dump(le, f'{PATH_TO_RINS}/RINS-kappa/workspace/src/task_2s/models/label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['is_training_image'] == 1]\n",
    "test_df = df[df['is_training_image'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotation_matrix(center, angle_degrees):\n",
    "    angle = np.radians(angle_degrees)\n",
    "    cos = np.cos(angle)\n",
    "    sin = np.sin(angle)\n",
    "    cx, cy = center\n",
    "    # Rotation matrix with translation to center\n",
    "    return np.array([\n",
    "        [cos, -sin, cx - cx * cos + cy * sin],\n",
    "        [sin,  cos, cy - cx * sin - cy * cos]\n",
    "    ])\n",
    "\n",
    "def rotate_bbox(corners, center, angle_degrees):\n",
    "    R = get_rotation_matrix(center, angle_degrees)\n",
    "    corners = np.hstack([corners, np.ones((4, 1))])  # Add homogeneous coordinate\n",
    "    rotated = (R @ corners.T).T\n",
    "    return rotated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_bounding_box(image, bbox):\n",
    "    x, y, w, h = bbox\n",
    "    return image.crop((x, y, x + w, y + h))\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Custom dataset\n",
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'image_path']\n",
    "        label = self.df.loc[idx, 'label']\n",
    "        angle = self.df.loc[idx, 'angle']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        H, W = image.size\n",
    "        # rotate the image\n",
    "        image = image.rotate(angle, expand=True)\n",
    "        # rotate the bounding box coordinates\n",
    "        x1, y1, w, h = self.df.loc[idx, ['bbox_x', 'bbox_y', 'bbox_width', 'bbox_height']].values\n",
    "        x2, y2 = x1 + w, y1 + h\n",
    "        \n",
    "        corners = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]])\n",
    "        rotated_corners = rotate_bbox(corners, center=(W/2, H/2), angle_degrees=angle)\n",
    "        x_coords = rotated_corners[:, 0]\n",
    "        y_coords = rotated_corners[:, 1]\n",
    "\n",
    "        new_bbox = [\n",
    "            x_coords.min(),\n",
    "            y_coords.min(),\n",
    "            x_coords.max(),\n",
    "            y_coords.max()\n",
    "        ]\n",
    "\n",
    "        bbox_x = new_bbox[0]\n",
    "        bbox_y = new_bbox[1]\n",
    "        bbox_width = new_bbox[2] - new_bbox[0]\n",
    "        bbox_height = new_bbox[3] - new_bbox[1]\n",
    "\n",
    "        image = crop_to_bounding_box(image, (bbox_x, bbox_y, bbox_width, bbox_height))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6153/721605506.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['angle'] = [0 for i in range(len(test_df))]  # No rotation for test set\n"
     ]
    }
   ],
   "source": [
    "# increase train dataset size by augmenting images (rotation for -30, -15, 0, 15, 30 degrees)\n",
    "increased_train_df = pd.concat([train_df] * 5, ignore_index=True)\n",
    "values = list(increased_train_df.index.values % 5)\n",
    "angles = [[-30, -15, 0, 15, 30][i] for i in values]\n",
    "increased_train_df['angle'] = angles\n",
    "\n",
    "test_df['angle'] = [0 for i in range(len(test_df))]  # No rotation for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = BirdDataset(increased_train_df, transform=transform)\n",
    "test_dataset = BirdDataset(test_df, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/strazi/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/strazi/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load pretrained model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Replace the last layer\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7721, Acc: 86.78%\n",
      "Epoch 2, Loss: 0.0223, Acc: 99.97%\n",
      "Epoch 3, Loss: 0.0071, Acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    acc = 100. * correct / total\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Acc: {acc:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.33%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100. * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'{PATH_TO_RINS}/RINS-kappa/workspace/src/task_2s/models/bird_species_model.pth'\n",
    "torch.save(model, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
