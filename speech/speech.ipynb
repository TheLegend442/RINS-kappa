{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "import speech_recognition as sr\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "str = \"002.Laysan_Albatross 012.Yellow_headed_Blackbird 014.Indigo_Bunting 025.Pelagic_Cormorant 029.American_Crow 033.Yellow_billed_Cuckoo 035.Purple_Finch 042.Vermilion_Flycatcher 048.European_Goldfinch 050.Eared_Grebe 059.California_Gull 068.Ruby_throated_Hummingbird 073.Blue_Jay 081.Pied_Kingfisher 095.Baltimore_Oriole 101.White_Pelican 106.Horned_Puffin 108.White_necked_Raven 112.Great_Grey_Shrike 118.House_Sparrow 134.Cape_Glossy_Starling 138.Tree_Swallow 144.Common_Tern 191.Red_headed_Woodpecker\"\n",
    "l = str.split(\" \")\n",
    "l = [i.split(\".\")[1] for i in l]\n",
    "l = [i.replace(\"_\", \" \").lower() for i in l]\n",
    "list_of_birds = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available microphones:\n",
      "0: HDA NVidia: HDMI 0 (hw:0,3)\n",
      "1: HDA NVidia: HDMI 1 (hw:0,7)\n",
      "2: HDA NVidia: HDMI 2 (hw:0,8)\n",
      "3: HDA NVidia: HDMI 3 (hw:0,9)\n",
      "4: HD-Audio Generic: HDMI 0 (hw:1,3)\n",
      "5: HD-Audio Generic: ALC285 Analog (hw:2,0)\n",
      "6: hdmi\n",
      "7: pulse\n",
      "8: default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    }
   ],
   "source": [
    "print(\"Available microphones:\")\n",
    "for index, name in enumerate(sr.Microphone.list_microphone_names()):\n",
    "    print(f\"{index}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HDA NVidia: HDMI 0 (hw:0,3)', 'HDA NVidia: HDMI 1 (hw:0,7)', 'HDA NVidia: HDMI 2 (hw:0,8)', 'HDA NVidia: HDMI 3 (hw:0,9)', 'HD-Audio Generic: HDMI 0 (hw:1,3)', 'HD-Audio Generic: ALC285 Analog (hw:2,0)', 'hdmi', 'pulse', 'default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "print(sr.Microphone.list_microphone_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Processing...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exiting program.\n"
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        try:\n",
    "            with sr.Microphone(device_index=5) as source:\n",
    "                print(\"Listening...\")\n",
    "                recognizer.adjust_for_ambient_noise(source, duration=0.2)\n",
    "                audio = recognizer.listen(source)\n",
    "                print(\"Processing...\")\n",
    "                text = recognizer.recognize_google(audio, language=\"en-US\")\n",
    "                text = text.lower()\n",
    "                print(\"You said:\", text)\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, I did not understand that.\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nExiting program.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Processing...\n",
      "You said: hello\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        audio = recognizer.listen(source)\n",
    "        print(\"Processing...\")\n",
    "        text = recognizer.recognize_google(audio, language=\"en-US\")\n",
    "        text = text.lower()\n",
    "        print(\"You said:\", text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sorry, I did not understand that.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 08:16:28.411 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n",
      "2025-05-19 08:16:28.415 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n",
      "2025-05-19 08:16:28.416 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n",
      "2025-05-19 08:16:28.417 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n",
      "2025-05-19 08:16:28.419 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n",
      "2025-05-19 08:16:28.420 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n"
     ]
    }
   ],
   "source": [
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 130)         # words per minute\n",
    "engine.setProperty('volume', 1)       # 0.0–1.0\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[111].id)  # pick a voice - I pick Sandy\n",
    "\n",
    "engine.say(\"Hello! Your bird catalogue is ready.\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voices = engine.getProperty('voices')\n",
    "# for i, v in enumerate(voices):\n",
    "#     if 'en_US' in v.languages:\n",
    "#         print(f\"{i}: id={v.id!r}\")\n",
    "#         print(f\"   name        : {v.name}\")\n",
    "#         print(f\"   languages   : {v.languages}\")\n",
    "#         print(f\"   gender      : {v.gender}\")\n",
    "#         print(f\"   age         : {v.age}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.say(\"eared grebe\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.say(\"Hello dear lady, which is your favorite bird?\")\n",
    "engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_words = [snap_bird(w) for w in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_birds(text, birds, threshold=85):\n",
    "    \"\"\"\n",
    "    Find substrings in `text` that closely match any bird name in `birds`\n",
    "    and replace them with the canonical spelling.\n",
    "    \"\"\"\n",
    "    words = text.split()            # coarse tokenisation\n",
    "    fixed = []\n",
    "    i = 0\n",
    "    best_best = \"\"\n",
    "    best_score = 0\n",
    "    while i < len(words):\n",
    "        # try to match up to 3‑word windows (adjust as needed)\n",
    "        matched = False\n",
    "        for window in range(3, 0, -1):\n",
    "            chunk = \" \".join(words[i:i+window])\n",
    "            if not chunk:\n",
    "                continue\n",
    "            best, score, _ = process.extractOne(\n",
    "                chunk,\n",
    "                birds,\n",
    "                scorer=fuzz.WRatio\n",
    "            )\n",
    "            if score >= threshold and score > best_score:\n",
    "                fixed.append(best)  # canonical bird name\n",
    "                i += window\n",
    "                matched = True\n",
    "                best_best = best\n",
    "                best_score = score\n",
    "                break\n",
    "        if not matched:\n",
    "            fixed.append(words[i])\n",
    "            i += 1\n",
    "    return best_best\n",
    "    # return \" \".join(fixed)\n",
    "    \n",
    "text = \"\"\n",
    "\n",
    "try:\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        audio = recognizer.listen(source)\n",
    "        print(\"Processing...\")\n",
    "        text = recognizer.recognize_google(audio, language=\"en-US\")\n",
    "        text = text.lower()\n",
    "        # print(\"You said:\", text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sorry, I did not understand that.\")\n",
    "\n",
    "clean_text = snap_birds(text, list_of_birds, threshold=90)\n",
    "print(\"You said: \", text)\n",
    "print(\"Bird species: \", clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['laysan albatross', 'yellow headed blackbird', 'indigo bunting', 'pelagic cormorant', 'american crow', 'yellow billed cuckoo', 'purple finch', 'vermilion flycatcher', 'european goldfinch', 'eared grebe', 'california gull', 'ruby throated hummingbird', 'blue jay', 'pied kingfisher', 'baltimore oriole', 'white pelican', 'horned puffin', 'white necked raven', 'great grey shrike', 'house sparrow', 'cape glossy starling', 'tree swallow', 'common tern', 'red headed woodpecker']\n"
     ]
    }
   ],
   "source": [
    "print(list_of_birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from models/vosk-model-small-en-us-0.15/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from models/vosk-model-small-en-us-0.15/graph/HCLr.fst models/vosk-model-small-en-us-0.15/graph/Gr.fst\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json, queue, sys, time\n",
    "import sounddevice as sd\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "MODEL_PATH = \"models/vosk-model-small-en-us-0.15\"\n",
    "SAMPLE_RATE = 16000  # model sample rate\n",
    "\n",
    "# 1. Load model\n",
    "model = Model(MODEL_PATH)\n",
    "\n",
    "# 2. Build phrase-bias JSON (not a hard grammar)\n",
    "grammar_json = json.dumps({\"phrase_list\": list_of_birds})\n",
    "rec = KaldiRecognizer(model, SAMPLE_RATE, grammar_json)\n",
    "\n",
    "# # 3. rapidfuzz helper\n",
    "# def snap_birds(text, birds=BIRDS, threshold=85):\n",
    "#     words = text.split()\n",
    "#     fixed = []\n",
    "#     i = 0\n",
    "#     while i < len(words):\n",
    "#         matched = False\n",
    "#         for window in range(4, 0, -1):          # up to 4-word chunks\n",
    "#             chunk = \" \".join(words[i:i+window])\n",
    "#             if not chunk:\n",
    "#                 continue\n",
    "#             best, score, _ = process.extractOne(\n",
    "#                 chunk, birds, scorer=fuzz.WRatio\n",
    "#             )\n",
    "#             if score >= threshold:\n",
    "#                 fixed.append(best)              # canonical name\n",
    "#                 i += window\n",
    "#                 matched = True\n",
    "#                 break\n",
    "#         if not matched:\n",
    "#             fixed.append(words[i])\n",
    "#             i += 1\n",
    "#     return \" \".join(fixed)\n",
    "\n",
    "# 4. Audio callback\n",
    "q = queue.Queue()\n",
    "def callback(indata, frames, time_, status):\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    q.put(bytes(indata))\n",
    "\n",
    "# 5. Start stream + recognizer loop\n",
    "print(\"🎤  Speak; Ctrl-C to stop.\")\n",
    "with sd.RawInputStream(samplerate=SAMPLE_RATE,\n",
    "                       blocksize=8000,\n",
    "                       dtype=\"int16\",\n",
    "                       channels=1,\n",
    "                       callback=callback):\n",
    "\n",
    "    partial_printed = \"\"\n",
    "    try:\n",
    "        while True:\n",
    "            data = q.get()\n",
    "            if rec.AcceptWaveform(data):\n",
    "                result = json.loads(rec.Result())\n",
    "                text = result.get(\"text\", \"\")\n",
    "                if text:\n",
    "                    fixed = snap_birds(text.lower())\n",
    "                    print(f\"\\n✅  {fixed}\")\n",
    "                    partial_printed = \"\"\n",
    "            else:\n",
    "                # show partials in same line\n",
    "                partial = json.loads(rec.PartialResult()).get(\"partial\", \"\")\n",
    "                if partial and partial != partial_printed:\n",
    "                    sys.stdout.write(\"\\r… \" + partial + \"   \")\n",
    "                    sys.stdout.flush()\n",
    "                    partial_printed = partial\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nStopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import json, queue\n",
    "# import sounddevice as sd\n",
    "import keyboard\n",
    "# from vosk import Model, KaldiRecognizer\n",
    "\n",
    "# BIRDS = [\"blue jay\", \"great tit\", \"american crow\"]   # …\n",
    "# model = Model(\"models/vosk-model-small-en-us-0.15\")\n",
    "# rec   = KaldiRecognizer(model, 16000, json.dumps(BIRDS))\n",
    "\n",
    "# q = queue.Queue()\n",
    "# def audio_cb(indata, frames, time, status):\n",
    "#     q.put(bytes(indata))\n",
    "\n",
    "# def listen_once():\n",
    "#     with sd.RawInputStream(samplerate=16000, blocksize=8000,\n",
    "#                            dtype=\"int16\", channels=1,\n",
    "#                            callback=audio_cb):\n",
    "#         print(\"⏺️  Listening… release key to stop\")\n",
    "#         while keyboard.is_pressed('space'):\n",
    "#             try:\n",
    "#                 data = q.get(timeout=0.1)\n",
    "#                 if rec.AcceptWaveform(data):\n",
    "#                     print(json.loads(rec.Result())['text'])\n",
    "#             except queue.Empty:\n",
    "#                 pass\n",
    "#         print(\"⏹️  Paused\")\n",
    "\n",
    "print(\"Hold SPACE to talk.  Press ESC to quit.\")\n",
    "# while True:\n",
    "#     keyboard.wait('space')\n",
    "#     print(\"listening...\")\n",
    "#     if keyboard.is_pressed('esc'):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "import string\n",
    "from rapidfuzz import process, fuzz\n",
    "import pyttsx3\n",
    "import time\n",
    "\n",
    "# DURATION = 3  # seconds to record\n",
    "SAMPLE_RATE = 16000  # Whisper prefers 16000 Hz\n",
    "\n",
    "model = whisper.load_model(\"medium.en\")\n",
    "\n",
    "str = \"002.Laysan_Albatross 012.Yellow_headed_Blackbird 014.Indigo_Bunting 025.Pelagic_Cormorant 029.American_Crow 033.Yellow_billed_Cuckoo 035.Purple_Finch 042.Vermilion_Flycatcher 048.European_Goldfinch 050.Eared_Grebe 059.California_Gull 068.Ruby_throated_Hummingbird 073.Blue_Jay 081.Pied_Kingfisher 095.Baltimore_Oriole 101.White_Pelican 106.Horned_Puffin 108.White_necked_Raven 112.Great_Grey_Shrike 118.House_Sparrow 134.Cape_Glossy_Starling 138.Tree_Swallow 144.Common_Tern 191.Red_headed_Woodpecker\"\n",
    "l = str.split(\" \")\n",
    "l = [i.split(\".\")[1] for i in l]\n",
    "l = [i.replace(\"_\", \" \").lower() for i in l]\n",
    "list_of_birds = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_birds(text, birds, threshold=85):\n",
    "    words = text.split()\n",
    "    fixed = []\n",
    "    i = 0\n",
    "    best_best = None\n",
    "    best_score = 0\n",
    "    \n",
    "    while i < len(words):\n",
    "        matched = False\n",
    "        # Try windows of 3 and 2 words only (no 1-word chunks)\n",
    "        for window in [3, 2]:\n",
    "            chunk_words = words[i:i+window]\n",
    "            if len(chunk_words) < window:\n",
    "                continue\n",
    "            # Remove punctuation for better matching\n",
    "            chunk = \" \".join(word.strip(string.punctuation) for word in chunk_words)\n",
    "            if not chunk:\n",
    "                continue\n",
    "            best, score, _ = process.extractOne(chunk, birds, scorer=fuzz.WRatio)\n",
    "            print(f\"[DEBUG] '{chunk}' matched '{best}' with score {score}\")\n",
    "            if score >= threshold and score > best_score:\n",
    "                fixed.append(best)  # canonical bird name\n",
    "                i += window\n",
    "                matched = True\n",
    "                best_best = best\n",
    "                best_score = score\n",
    "                break  # no need to check smaller window if matched\n",
    "        if not matched:\n",
    "            fixed.append(words[i])\n",
    "            i += 1\n",
    "    return best_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_input(duration, playback=False, birds=None, sample_rate=16000):\n",
    "    print(\"🎤 Recording... Speak now.\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    print(\"📦 Recording finished. Transcribing...\")\n",
    "    if playback: sd.play(audio, sample_rate)\n",
    "\n",
    "    # Save to temporary WAV file\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmpfile:\n",
    "        wav.write(tmpfile.name, sample_rate, audio)\n",
    "        tmp_path = tmpfile.name\n",
    "\n",
    "    # Transcribe using Whisper\n",
    "    result = model.transcribe(tmp_path)\n",
    "    if birds:\n",
    "        # Find the best matching bird name\n",
    "        bird_name = snap_birds(result['text'].lower(), birds, threshold=70)\n",
    "\n",
    "    # Clean up\n",
    "    os.remove(tmp_path)\n",
    "\n",
    "    return result['text'], bird_name if birds else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bird_name(engine, birds):\n",
    "    bird_recongized = False\n",
    "\n",
    "    while not bird_recongized:\n",
    "        text, bird = get_user_input(4, playback=False, birds=birds)\n",
    "        print(\"Transcribed text:\", text)\n",
    "        print(\"Detected bird:\", bird)\n",
    "        if bird:\n",
    "            bird_recongized = True\n",
    "            return text, bird\n",
    "        else:\n",
    "            engine.say(\"Sorry, I couldn't identify the bird. Please try again.\")\n",
    "            engine.runAndWait()\n",
    "            time.sleep(4)\n",
    "\n",
    "def talk_to_female(engine, list_of_birds):\n",
    "    engine.say(\"Hello lady! Which is your favorite bird?\")\n",
    "    engine.runAndWait()\n",
    "    time.sleep(2)\n",
    "    _, bird = get_bird_name(engine, list_of_birds)\n",
    "    location = \"center\"\n",
    "    color = \"red\"\n",
    "    engine.say(f\"Thank you for letting me know.\")\n",
    "    engine.runAndWait()\n",
    "    engine.say(f'The {bird} is sitting on a {color} ring in the {location} part of the park.')\n",
    "    engine.runAndWait()\n",
    "\n",
    "\n",
    "def talk_to_male(engine, list_of_birds):\n",
    "    engine.say(\"Hello sir! Which is your favorite bird?\")\n",
    "    engine.runAndWait()\n",
    "    time.sleep(2)\n",
    "\n",
    "    bird_confirmed = False\n",
    "    _, pending_bird = get_bird_name(engine, list_of_birds)\n",
    "\n",
    "    while not bird_confirmed:\n",
    "        engine.say(f\"Are you sure that it is {pending_bird}?\")\n",
    "        engine.runAndWait()\n",
    "        time.sleep(2)\n",
    "        text, bird = get_user_input(4, playback=False, birds=list_of_birds)\n",
    "        print(\"Transcribed text:\", text)\n",
    "        print(\"Detected bird:\", bird)\n",
    "        if bird == None and (\"yes\" in text.lower()):\n",
    "            bird_confirmed = True\n",
    "            engine.say(f'Thanks for confirming that it is {pending_bird}.')\n",
    "            engine.runAndWait()\n",
    "            time.sleep(2)\n",
    "        if bird == pending_bird:\n",
    "            bird_confirmed = True\n",
    "            engine.say(f'Thanks for confirming that it is {pending_bird}.')\n",
    "            engine.runAndWait()\n",
    "            time.sleep(2)\n",
    "        else:\n",
    "            pending_bird = bird\n",
    "            time.sleep(4)\n",
    "\n",
    "        location = \"center\"\n",
    "        color = \"red\"\n",
    "        engine.say(f'The {pending_bird} is sitting on a {color} ring in the {location} part of the park.')\n",
    "        engine.runAndWait()\n",
    "\n",
    "    text, bird = get_user_input(4, playback=False, birds=list_of_birds)\n",
    "    print(\"Transcribed text:\", text)\n",
    "    print(\"Detected bird:\", bird)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = 'F'\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 140)         # words per minute\n",
    "engine.setProperty('volume', 1)       # 0.0–1.0\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[19].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤 Recording... Speak now.\n",
      "📦 Recording finished. Transcribing...\n",
      "[DEBUG] 'i like vermilion' matched 'vermilion flycatcher' with score 68.39999999999999\n",
      "[DEBUG] 'i like' matched 'great grey shrike' with score 60.00000000000001\n",
      "[DEBUG] 'like vermilion flycatcher' matched 'vermilion flycatcher' with score 95.0\n",
      "Transcribed text:  I like Vermilion Flycatcher\n",
      "Detected bird: vermilion flycatcher\n",
      "🎤 Recording... Speak now.\n",
      "📦 Recording finished. Transcribing...\n",
      "[DEBUG] 'in crows' matched 'american crow' with score 77.14285714285715\n",
      "Transcribed text:  In crows\n",
      "Detected bird: american crow\n",
      "🎤 Recording... Speak now.\n",
      "📦 Recording finished. Transcribing...\n",
      "[DEBUG] 'american krause' matched 'american crow' with score 72.38095238095238\n",
      "Transcribed text:  American Krause\n",
      "Detected bird: american crow\n",
      "🎤 Recording... Speak now.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtalk_to_male\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_of_birds\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 57\u001b[0m, in \u001b[0;36mtalk_to_male\u001b[0;34m(engine, list_of_birds)\u001b[0m\n\u001b[1;32m     52\u001b[0m         pending_bird \u001b[38;5;241m=\u001b[39m bird\n\u001b[1;32m     53\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 57\u001b[0m text, bird \u001b[38;5;241m=\u001b[39m \u001b[43mget_user_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbirds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlist_of_birds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscribed text:\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected bird:\u001b[39m\u001b[38;5;124m\"\u001b[39m, bird)\n",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m, in \u001b[0;36mget_user_input\u001b[0;34m(duration, playback, birds, sample_rate)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🎤 Recording... Speak now.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m audio \u001b[38;5;241m=\u001b[39m sd\u001b[38;5;241m.\u001b[39mrec(\u001b[38;5;28mint\u001b[39m(duration \u001b[38;5;241m*\u001b[39m sample_rate), samplerate\u001b[38;5;241m=\u001b[39msample_rate, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📦 Recording finished. Transcribing...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m playback: sd\u001b[38;5;241m.\u001b[39mplay(audio, sample_rate)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sounddevice.py:398\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(ignore_errors)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m\"\"\"Wait for `play()`/`rec()`/`playrec()` to be finished.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03mPlayback/recording can be stopped with a `KeyboardInterrupt`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _last_callback:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sounddevice.py:2653\u001b[0m, in \u001b[0;36m_CallbackContext.wait\u001b[0;34m(self, ignore_errors)\u001b[0m\n\u001b[1;32m   2647\u001b[0m \u001b[38;5;124;03m\"\"\"Wait for finished_callback.\u001b[39;00m\n\u001b[1;32m   2648\u001b[0m \n\u001b[1;32m   2649\u001b[0m \u001b[38;5;124;03mCan be interrupted with a KeyboardInterrupt.\u001b[39;00m\n\u001b[1;32m   2650\u001b[0m \n\u001b[1;32m   2651\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2653\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2654\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2655\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mclose(ignore_errors)\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "talk_to_male(engine, list_of_birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤 Recording... Speak now.\n",
      "📦 Recording finished. Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred