{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "str = \"002.Laysan_Albatross 012.Yellow_headed_Blackbird 014.Indigo_Bunting 025.Pelagic_Cormorant 029.American_Crow 033.Yellow_billed_Cuckoo 035.Purple_Finch 042.Vermilion_Flycatcher 048.European_Goldfinch 050.Eared_Grebe 059.California_Gull 068.Ruby_throated_Hummingbird 073.Blue_Jay 081.Pied_Kingfisher 095.Baltimore_Oriole 101.White_Pelican 106.Horned_Puffin 108.White_necked_Raven 112.Great_Grey_Shrike 118.House_Sparrow 134.Cape_Glossy_Starling 138.Tree_Swallow 144.Common_Tern 191.Red_headed_Woodpecker\"\n",
    "l = str.split(\" \")\n",
    "l = [i.split(\".\")[1] for i in l]\n",
    "l = [i.replace(\"_\", \" \").lower() for i in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_birds = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['laysan albatross',\n",
       " 'yellow headed blackbird',\n",
       " 'indigo bunting',\n",
       " 'pelagic cormorant',\n",
       " 'american crow',\n",
       " 'yellow billed cuckoo',\n",
       " 'purple finch',\n",
       " 'vermilion flycatcher',\n",
       " 'european goldfinch',\n",
       " 'eared grebe',\n",
       " 'california gull',\n",
       " 'ruby throated hummingbird',\n",
       " 'blue jay',\n",
       " 'pied kingfisher',\n",
       " 'baltimore oriole',\n",
       " 'white pelican',\n",
       " 'horned puffin',\n",
       " 'white necked raven',\n",
       " 'great grey shrike',\n",
       " 'house sparrow',\n",
       " 'cape glossy starling',\n",
       " 'tree swallow',\n",
       " 'common tern',\n",
       " 'red headed woodpecker']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/thelegend442/Desktop/University/letnik_3/RINS/RINS-kappa/speech/speech.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thelegend442/Desktop/University/letnik_3/RINS/RINS-kappa/speech/speech.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mListening...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thelegend442/Desktop/University/letnik_3/RINS/RINS-kappa/speech/speech.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m recognizer\u001b[39m.\u001b[39madjust_for_ambient_noise(source, duration\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/thelegend442/Desktop/University/letnik_3/RINS/RINS-kappa/speech/speech.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m audio \u001b[39m=\u001b[39m recognizer\u001b[39m.\u001b[39;49mlisten(source)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thelegend442/Desktop/University/letnik_3/RINS/RINS-kappa/speech/speech.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mProcessing...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thelegend442/Desktop/University/letnik_3/RINS/RINS-kappa/speech/speech.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m text \u001b[39m=\u001b[39m recognizer\u001b[39m.\u001b[39mrecognize_google(audio, language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39men-US\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/speech_recognition/__init__.py:460\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[1;32m    458\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[1;32m    459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m result:\n\u001b[1;32m    461\u001b[0m         \u001b[39mreturn\u001b[39;49;00m a\n\u001b[1;32m    462\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/speech_recognition/__init__.py:530\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[39mif\u001b[39;00m phrase_time_limit \u001b[39mand\u001b[39;00m elapsed_time \u001b[39m-\u001b[39m phrase_start_time \u001b[39m>\u001b[39m phrase_time_limit:\n\u001b[1;32m    528\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m buffer \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mread(source\u001b[39m.\u001b[39;49mCHUNK)\n\u001b[1;32m    531\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mbreak\u001b[39;00m  \u001b[39m# reached end of the stream\u001b[39;00m\n\u001b[1;32m    532\u001b[0m frames\u001b[39m.\u001b[39mappend(buffer)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/speech_recognition/__init__.py:191\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, size):\n\u001b[0;32m--> 191\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpyaudio_stream\u001b[39m.\u001b[39;49mread(size, exception_on_overflow\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pyaudio/__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_input:\n\u001b[1;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot input stream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m--> 570\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39;49mread_stream(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream, num_frames,\n\u001b[1;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Listening...\")\n",
    "            recognizer.adjust_for_ambient_noise(source, duration=0.2)\n",
    "            audio = recognizer.listen(source)\n",
    "            print(\"Processing...\")\n",
    "            text = recognizer.recognize_google(audio, language=\"en-US\")\n",
    "            text = text.lower()\n",
    "            print(\"You said:\", text)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry, I did not understand that.\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Processing...\n",
      "You said: hello\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        audio = recognizer.listen(source)\n",
    "        print(\"Processing...\")\n",
    "        text = recognizer.recognize_google(audio, language=\"en-US\")\n",
    "        text = text.lower()\n",
    "        print(\"You said:\", text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sorry, I did not understand that.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 08:16:28.411 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n",
      "2025-05-19 08:16:28.415 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n",
      "2025-05-19 08:16:28.416 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n",
      "2025-05-19 08:16:28.417 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n",
      "2025-05-19 08:16:28.419 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n",
      "2025-05-19 08:16:28.420 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n"
     ]
    }
   ],
   "source": [
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 130)         # words per minute\n",
    "engine.setProperty('volume', 1)       # 0.0‚Äì1.0\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[111].id)  # pick a voice - I pick Sandy\n",
    "\n",
    "engine.say(\"Hello! Your bird catalogue is ready.\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voices = engine.getProperty('voices')\n",
    "# for i, v in enumerate(voices):\n",
    "#     if 'en_US' in v.languages:\n",
    "#         print(f\"{i}: id={v.id!r}\")\n",
    "#         print(f\"   name        : {v.name}\")\n",
    "#         print(f\"   languages   : {v.languages}\")\n",
    "#         print(f\"   gender      : {v.gender}\")\n",
    "#         print(f\"   age         : {v.age}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.say(\"eared grebe\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.say(\"Hello dear lady, which is your favorite bird?\")\n",
    "engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "# def snap_bird(word):\n",
    "#     match, score, _ = process.extractOne(word, list_of_birds, scorer=fuzz.WRatio)\n",
    "#     return match if score > 80 else word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_words = [snap_bird(w) for w in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Processing...\n",
      "Sorry, I did not understand that.\n",
      "You said:  \n",
      "Bird species:  \n"
     ]
    }
   ],
   "source": [
    "def snap_birds(text, birds, threshold=85):\n",
    "    \"\"\"\n",
    "    Find substrings in `text` that closely match any bird name in `birds`\n",
    "    and replace them with the canonical spelling.\n",
    "    \"\"\"\n",
    "    words = text.split()            # coarse tokenisation\n",
    "    fixed = []\n",
    "    i = 0\n",
    "    best_best = \"\"\n",
    "    best_score = 0\n",
    "    while i < len(words):\n",
    "        # try to match up to 3‚Äëword windows (adjust as needed)\n",
    "        matched = False\n",
    "        for window in range(3, 0, -1):\n",
    "            chunk = \" \".join(words[i:i+window])\n",
    "            if not chunk:\n",
    "                continue\n",
    "            best, score, _ = process.extractOne(\n",
    "                chunk,\n",
    "                birds,\n",
    "                scorer=fuzz.WRatio\n",
    "            )\n",
    "            if score >= threshold and score > best_score:\n",
    "                fixed.append(best)  # canonical bird name\n",
    "                i += window\n",
    "                matched = True\n",
    "                best_best = best\n",
    "                best_score = score\n",
    "                break\n",
    "        if not matched:\n",
    "            fixed.append(words[i])\n",
    "            i += 1\n",
    "    return best_best\n",
    "    # return \" \".join(fixed)\n",
    "    \n",
    "text = \"\"\n",
    "\n",
    "try:\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        audio = recognizer.listen(source)\n",
    "        print(\"Processing...\")\n",
    "        text = recognizer.recognize_google(audio, language=\"en-US\")\n",
    "        text = text.lower()\n",
    "        # print(\"You said:\", text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sorry, I did not understand that.\")\n",
    "\n",
    "clean_text = snap_birds(text, list_of_birds, threshold=90)\n",
    "print(\"You said: \", text)\n",
    "print(\"Bird species: \", clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['laysan albatross', 'yellow headed blackbird', 'indigo bunting', 'pelagic cormorant', 'american crow', 'yellow billed cuckoo', 'purple finch', 'vermilion flycatcher', 'european goldfinch', 'eared grebe', 'california gull', 'ruby throated hummingbird', 'blue jay', 'pied kingfisher', 'baltimore oriole', 'white pelican', 'horned puffin', 'white necked raven', 'great grey shrike', 'house sparrow', 'cape glossy starling', 'tree swallow', 'common tern', 'red headed woodpecker']\n"
     ]
    }
   ],
   "source": [
    "print(list_of_birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from models/vosk-model-small-en-us-0.15/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from models/vosk-model-small-en-us-0.15/graph/HCLr.fst models/vosk-model-small-en-us-0.15/graph/Gr.fst\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json, queue, sys, time\n",
    "import sounddevice as sd\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "MODEL_PATH = \"models/vosk-model-small-en-us-0.15\"\n",
    "SAMPLE_RATE = 16000  # model sample rate\n",
    "\n",
    "# 1. Load model\n",
    "model = Model(MODEL_PATH)\n",
    "\n",
    "# 2. Build phrase-bias JSON (not a hard grammar)\n",
    "grammar_json = json.dumps({\"phrase_list\": list_of_birds})\n",
    "rec = KaldiRecognizer(model, SAMPLE_RATE, grammar_json)\n",
    "\n",
    "# # 3. rapidfuzz helper\n",
    "# def snap_birds(text, birds=BIRDS, threshold=85):\n",
    "#     words = text.split()\n",
    "#     fixed = []\n",
    "#     i = 0\n",
    "#     while i < len(words):\n",
    "#         matched = False\n",
    "#         for window in range(4, 0, -1):          # up to 4-word chunks\n",
    "#             chunk = \" \".join(words[i:i+window])\n",
    "#             if not chunk:\n",
    "#                 continue\n",
    "#             best, score, _ = process.extractOne(\n",
    "#                 chunk, birds, scorer=fuzz.WRatio\n",
    "#             )\n",
    "#             if score >= threshold:\n",
    "#                 fixed.append(best)              # canonical name\n",
    "#                 i += window\n",
    "#                 matched = True\n",
    "#                 break\n",
    "#         if not matched:\n",
    "#             fixed.append(words[i])\n",
    "#             i += 1\n",
    "#     return \" \".join(fixed)\n",
    "\n",
    "# 4. Audio callback\n",
    "q = queue.Queue()\n",
    "def callback(indata, frames, time_, status):\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    q.put(bytes(indata))\n",
    "\n",
    "# 5. Start stream + recognizer loop\n",
    "print(\"üé§  Speak; Ctrl-C to stop.\")\n",
    "with sd.RawInputStream(samplerate=SAMPLE_RATE,\n",
    "                       blocksize=8000,\n",
    "                       dtype=\"int16\",\n",
    "                       channels=1,\n",
    "                       callback=callback):\n",
    "\n",
    "    partial_printed = \"\"\n",
    "    try:\n",
    "        while True:\n",
    "            data = q.get()\n",
    "            if rec.AcceptWaveform(data):\n",
    "                result = json.loads(rec.Result())\n",
    "                text = result.get(\"text\", \"\")\n",
    "                if text:\n",
    "                    fixed = snap_birds(text.lower())\n",
    "                    print(f\"\\n‚úÖ  {fixed}\")\n",
    "                    partial_printed = \"\"\n",
    "            else:\n",
    "                # show partials in same line\n",
    "                partial = json.loads(rec.PartialResult()).get(\"partial\", \"\")\n",
    "                if partial and partial != partial_printed:\n",
    "                    sys.stdout.write(\"\\r‚Ä¶ \" + partial + \"   \")\n",
    "                    sys.stdout.flush()\n",
    "                    partial_printed = partial\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nStopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import json, queue\n",
    "# import sounddevice as sd\n",
    "import keyboard\n",
    "# from vosk import Model, KaldiRecognizer\n",
    "\n",
    "# BIRDS = [\"blue jay\", \"great tit\", \"american crow\"]   # ‚Ä¶\n",
    "# model = Model(\"models/vosk-model-small-en-us-0.15\")\n",
    "# rec   = KaldiRecognizer(model, 16000, json.dumps(BIRDS))\n",
    "\n",
    "# q = queue.Queue()\n",
    "# def audio_cb(indata, frames, time, status):\n",
    "#     q.put(bytes(indata))\n",
    "\n",
    "# def listen_once():\n",
    "#     with sd.RawInputStream(samplerate=16000, blocksize=8000,\n",
    "#                            dtype=\"int16\", channels=1,\n",
    "#                            callback=audio_cb):\n",
    "#         print(\"‚è∫Ô∏è  Listening‚Ä¶ release key to stop\")\n",
    "#         while keyboard.is_pressed('space'):\n",
    "#             try:\n",
    "#                 data = q.get(timeout=0.1)\n",
    "#                 if rec.AcceptWaveform(data):\n",
    "#                     print(json.loads(rec.Result())['text'])\n",
    "#             except queue.Empty:\n",
    "#                 pass\n",
    "#         print(\"‚èπÔ∏è  Paused\")\n",
    "\n",
    "print(\"Hold SPACE to talk.  Press ESC to quit.\")\n",
    "# while True:\n",
    "#     keyboard.wait('space')\n",
    "#     print(\"listening...\")\n",
    "#     if keyboard.is_pressed('esc'):\n",
    "#         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
