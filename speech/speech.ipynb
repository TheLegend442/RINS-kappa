{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "import speech_recognition as sr\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "str = \"002.Laysan_Albatross 012.Yellow_headed_Blackbird 014.Indigo_Bunting 025.Pelagic_Cormorant 029.American_Crow 033.Yellow_billed_Cuckoo 035.Purple_Finch 042.Vermilion_Flycatcher 048.European_Goldfinch 050.Eared_Grebe 059.California_Gull 068.Ruby_throated_Hummingbird 073.Blue_Jay 081.Pied_Kingfisher 095.Baltimore_Oriole 101.White_Pelican 106.Horned_Puffin 108.White_necked_Raven 112.Great_Grey_Shrike 118.House_Sparrow 134.Cape_Glossy_Starling 138.Tree_Swallow 144.Common_Tern 191.Red_headed_Woodpecker\"\n",
    "l = str.split(\" \")\n",
    "l = [i.split(\".\")[1] for i in l]\n",
    "l = [i.replace(\"_\", \" \").lower() for i in l]\n",
    "list_of_birds = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available microphones:\n",
      "0: HDA NVidia: HDMI 0 (hw:0,3)\n",
      "1: HDA NVidia: HDMI 1 (hw:0,7)\n",
      "2: HDA NVidia: HDMI 2 (hw:0,8)\n",
      "3: HDA NVidia: HDMI 3 (hw:0,9)\n",
      "4: HD-Audio Generic: HDMI 0 (hw:1,3)\n",
      "5: HD-Audio Generic: ALC285 Analog (hw:2,0)\n",
      "6: hdmi\n",
      "7: pulse\n",
      "8: default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    }
   ],
   "source": [
    "print(\"Available microphones:\")\n",
    "for index, name in enumerate(sr.Microphone.list_microphone_names()):\n",
    "    print(f\"{index}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HDA NVidia: HDMI 0 (hw:0,3)', 'HDA NVidia: HDMI 1 (hw:0,7)', 'HDA NVidia: HDMI 2 (hw:0,8)', 'HDA NVidia: HDMI 3 (hw:0,9)', 'HD-Audio Generic: HDMI 0 (hw:1,3)', 'HD-Audio Generic: ALC285 Analog (hw:2,0)', 'hdmi', 'pulse', 'default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "print(sr.Microphone.list_microphone_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Processing...\n",
      "Sorry, I did not understand that.\n",
      "Listening...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dmix.c:1032:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exiting program.\n"
     ]
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        try:\n",
    "            with sr.Microphone(device_index=5) as source:\n",
    "                print(\"Listening...\")\n",
    "                recognizer.adjust_for_ambient_noise(source, duration=0.2)\n",
    "                audio = recognizer.listen(source)\n",
    "                print(\"Processing...\")\n",
    "                text = recognizer.recognize_google(audio, language=\"en-US\")\n",
    "                text = text.lower()\n",
    "                print(\"You said:\", text)\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, I did not understand that.\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nExiting program.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Processing...\n",
      "You said: hello\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        audio = recognizer.listen(source)\n",
    "        print(\"Processing...\")\n",
    "        text = recognizer.recognize_google(audio, language=\"en-US\")\n",
    "        text = text.lower()\n",
    "        print(\"You said:\", text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sorry, I did not understand that.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 08:16:28.411 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n",
      "2025-05-19 08:16:28.415 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n",
      "2025-05-19 08:16:28.416 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n",
      "2025-05-19 08:16:28.417 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n",
      "2025-05-19 08:16:28.419 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n",
      "2025-05-19 08:16:28.420 python[17252:303161804] Could not retrieve voice [AVSpeechSynthesisProviderVoice 0x120161250] Name: Sandy, Identifier: com.apple.eloquence.en-US.Sandy, Supported Languages (\n",
      "    \"en-US\"\n",
      "), Age: 0, Gender: 0, Size: 0, Version: (null)\n"
     ]
    }
   ],
   "source": [
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 130)         # words per minute\n",
    "engine.setProperty('volume', 1)       # 0.0‚Äì1.0\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[111].id)  # pick a voice - I pick Sandy\n",
    "\n",
    "engine.say(\"Hello! Your bird catalogue is ready.\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voices = engine.getProperty('voices')\n",
    "# for i, v in enumerate(voices):\n",
    "#     if 'en_US' in v.languages:\n",
    "#         print(f\"{i}: id={v.id!r}\")\n",
    "#         print(f\"   name        : {v.name}\")\n",
    "#         print(f\"   languages   : {v.languages}\")\n",
    "#         print(f\"   gender      : {v.gender}\")\n",
    "#         print(f\"   age         : {v.age}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.say(\"eared grebe\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.say(\"Hello dear lady, which is your favorite bird?\")\n",
    "engine.runAndWait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_words = [snap_bird(w) for w in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_birds(text, birds, threshold=85):\n",
    "    \"\"\"\n",
    "    Find substrings in `text` that closely match any bird name in `birds`\n",
    "    and replace them with the canonical spelling.\n",
    "    \"\"\"\n",
    "    words = text.split()            # coarse tokenisation\n",
    "    fixed = []\n",
    "    i = 0\n",
    "    best_best = \"\"\n",
    "    best_score = 0\n",
    "    while i < len(words):\n",
    "        # try to match up to 3‚Äëword windows (adjust as needed)\n",
    "        matched = False\n",
    "        for window in range(3, 0, -1):\n",
    "            chunk = \" \".join(words[i:i+window])\n",
    "            if not chunk:\n",
    "                continue\n",
    "            best, score, _ = process.extractOne(\n",
    "                chunk,\n",
    "                birds,\n",
    "                scorer=fuzz.WRatio\n",
    "            )\n",
    "            if score >= threshold and score > best_score:\n",
    "                fixed.append(best)  # canonical bird name\n",
    "                i += window\n",
    "                matched = True\n",
    "                best_best = best\n",
    "                best_score = score\n",
    "                break\n",
    "        if not matched:\n",
    "            fixed.append(words[i])\n",
    "            i += 1\n",
    "    return best_best\n",
    "    # return \" \".join(fixed)\n",
    "    \n",
    "text = \"\"\n",
    "\n",
    "try:\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        audio = recognizer.listen(source)\n",
    "        print(\"Processing...\")\n",
    "        text = recognizer.recognize_google(audio, language=\"en-US\")\n",
    "        text = text.lower()\n",
    "        # print(\"You said:\", text)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sorry, I did not understand that.\")\n",
    "\n",
    "clean_text = snap_birds(text, list_of_birds, threshold=90)\n",
    "print(\"You said: \", text)\n",
    "print(\"Bird species: \", clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['laysan albatross', 'yellow headed blackbird', 'indigo bunting', 'pelagic cormorant', 'american crow', 'yellow billed cuckoo', 'purple finch', 'vermilion flycatcher', 'european goldfinch', 'eared grebe', 'california gull', 'ruby throated hummingbird', 'blue jay', 'pied kingfisher', 'baltimore oriole', 'white pelican', 'horned puffin', 'white necked raven', 'great grey shrike', 'house sparrow', 'cape glossy starling', 'tree swallow', 'common tern', 'red headed woodpecker']\n"
     ]
    }
   ],
   "source": [
    "print(list_of_birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from models/vosk-model-small-en-us-0.15/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from models/vosk-model-small-en-us-0.15/graph/HCLr.fst models/vosk-model-small-en-us-0.15/graph/Gr.fst\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json, queue, sys, time\n",
    "import sounddevice as sd\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "MODEL_PATH = \"models/vosk-model-small-en-us-0.15\"\n",
    "SAMPLE_RATE = 16000  # model sample rate\n",
    "\n",
    "# 1. Load model\n",
    "model = Model(MODEL_PATH)\n",
    "\n",
    "# 2. Build phrase-bias JSON (not a hard grammar)\n",
    "grammar_json = json.dumps({\"phrase_list\": list_of_birds})\n",
    "rec = KaldiRecognizer(model, SAMPLE_RATE, grammar_json)\n",
    "\n",
    "# # 3. rapidfuzz helper\n",
    "# def snap_birds(text, birds=BIRDS, threshold=85):\n",
    "#     words = text.split()\n",
    "#     fixed = []\n",
    "#     i = 0\n",
    "#     while i < len(words):\n",
    "#         matched = False\n",
    "#         for window in range(4, 0, -1):          # up to 4-word chunks\n",
    "#             chunk = \" \".join(words[i:i+window])\n",
    "#             if not chunk:\n",
    "#                 continue\n",
    "#             best, score, _ = process.extractOne(\n",
    "#                 chunk, birds, scorer=fuzz.WRatio\n",
    "#             )\n",
    "#             if score >= threshold:\n",
    "#                 fixed.append(best)              # canonical name\n",
    "#                 i += window\n",
    "#                 matched = True\n",
    "#                 break\n",
    "#         if not matched:\n",
    "#             fixed.append(words[i])\n",
    "#             i += 1\n",
    "#     return \" \".join(fixed)\n",
    "\n",
    "# 4. Audio callback\n",
    "q = queue.Queue()\n",
    "def callback(indata, frames, time_, status):\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    q.put(bytes(indata))\n",
    "\n",
    "# 5. Start stream + recognizer loop\n",
    "print(\"üé§  Speak; Ctrl-C to stop.\")\n",
    "with sd.RawInputStream(samplerate=SAMPLE_RATE,\n",
    "                       blocksize=8000,\n",
    "                       dtype=\"int16\",\n",
    "                       channels=1,\n",
    "                       callback=callback):\n",
    "\n",
    "    partial_printed = \"\"\n",
    "    try:\n",
    "        while True:\n",
    "            data = q.get()\n",
    "            if rec.AcceptWaveform(data):\n",
    "                result = json.loads(rec.Result())\n",
    "                text = result.get(\"text\", \"\")\n",
    "                if text:\n",
    "                    fixed = snap_birds(text.lower())\n",
    "                    print(f\"\\n‚úÖ  {fixed}\")\n",
    "                    partial_printed = \"\"\n",
    "            else:\n",
    "                # show partials in same line\n",
    "                partial = json.loads(rec.PartialResult()).get(\"partial\", \"\")\n",
    "                if partial and partial != partial_printed:\n",
    "                    sys.stdout.write(\"\\r‚Ä¶ \" + partial + \"   \")\n",
    "                    sys.stdout.flush()\n",
    "                    partial_printed = partial\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nStopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# import json, queue\n",
    "# import sounddevice as sd\n",
    "import keyboard\n",
    "# from vosk import Model, KaldiRecognizer\n",
    "\n",
    "# BIRDS = [\"blue jay\", \"great tit\", \"american crow\"]   # ‚Ä¶\n",
    "# model = Model(\"models/vosk-model-small-en-us-0.15\")\n",
    "# rec   = KaldiRecognizer(model, 16000, json.dumps(BIRDS))\n",
    "\n",
    "# q = queue.Queue()\n",
    "# def audio_cb(indata, frames, time, status):\n",
    "#     q.put(bytes(indata))\n",
    "\n",
    "# def listen_once():\n",
    "#     with sd.RawInputStream(samplerate=16000, blocksize=8000,\n",
    "#                            dtype=\"int16\", channels=1,\n",
    "#                            callback=audio_cb):\n",
    "#         print(\"‚è∫Ô∏è  Listening‚Ä¶ release key to stop\")\n",
    "#         while keyboard.is_pressed('space'):\n",
    "#             try:\n",
    "#                 data = q.get(timeout=0.1)\n",
    "#                 if rec.AcceptWaveform(data):\n",
    "#                     print(json.loads(rec.Result())['text'])\n",
    "#             except queue.Empty:\n",
    "#                 pass\n",
    "#         print(\"‚èπÔ∏è  Paused\")\n",
    "\n",
    "print(\"Hold SPACE to talk.  Press ESC to quit.\")\n",
    "# while True:\n",
    "#     keyboard.wait('space')\n",
    "#     print(\"listening...\")\n",
    "#     if keyboard.is_pressed('esc'):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "import string\n",
    "from rapidfuzz import process, fuzz\n",
    "import pyttsx3\n",
    "import time\n",
    "\n",
    "# DURATION = 3  # seconds to record\n",
    "SAMPLE_RATE = 16000  # Whisper prefers 16000 Hz\n",
    "\n",
    "model = whisper.load_model(\"medium.en\")\n",
    "\n",
    "str = \"002.Laysan_Albatross 012.Yellow_headed_Blackbird 014.Indigo_Bunting 025.Pelagic_Cormorant 029.American_Crow 033.Yellow_billed_Cuckoo 035.Purple_Finch 042.Vermilion_Flycatcher 048.European_Goldfinch 050.Eared_Grebe 059.California_Gull 068.Ruby_throated_Hummingbird 073.Blue_Jay 081.Pied_Kingfisher 095.Baltimore_Oriole 101.White_Pelican 106.Horned_Puffin 108.White_necked_Raven 112.Great_Grey_Shrike 118.House_Sparrow 134.Cape_Glossy_Starling 138.Tree_Swallow 144.Common_Tern 191.Red_headed_Woodpecker\"\n",
    "l = str.split(\" \")\n",
    "l = [i.split(\".\")[1] for i in l]\n",
    "l = [i.replace(\"_\", \" \").lower() for i in l]\n",
    "list_of_birds = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_birds(text, birds, threshold=85):\n",
    "    words = text.split()\n",
    "    fixed = []\n",
    "    i = 0\n",
    "    best_best = None\n",
    "    best_score = 0\n",
    "    \n",
    "    while i < len(words):\n",
    "        matched = False\n",
    "        # Try windows of 3 and 2 words only (no 1-word chunks)\n",
    "        for window in [3, 2]:\n",
    "            chunk_words = words[i:i+window]\n",
    "            if len(chunk_words) < window:\n",
    "                continue\n",
    "            # Remove punctuation for better matching\n",
    "            chunk = \" \".join(word.strip(string.punctuation) for word in chunk_words)\n",
    "            if not chunk:\n",
    "                continue\n",
    "            best, score, _ = process.extractOne(chunk, birds, scorer=fuzz.WRatio)\n",
    "            #print(f\"[DEBUG] '{chunk}' matched '{best}' with score {score}\")\n",
    "            if score >= threshold and score > best_score:\n",
    "                fixed.append(best)  # canonical bird name\n",
    "                i += window\n",
    "                matched = True\n",
    "                best_best = best\n",
    "                best_score = score\n",
    "                break  # no need to check smaller window if matched\n",
    "        if not matched:\n",
    "            fixed.append(words[i])\n",
    "            i += 1\n",
    "    return best_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_input(duration, playback=False, birds=None, sample_rate=16000):\n",
    "    print(\"üé§ Recording... Speak now.\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    print(\"üì¶ Recording finished. Transcribing...\")\n",
    "    if playback: sd.play(audio, sample_rate)\n",
    "\n",
    "    # Save to temporary WAV file\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmpfile:\n",
    "        wav.write(tmpfile.name, sample_rate, audio)\n",
    "        tmp_path = tmpfile.name\n",
    "\n",
    "    # Transcribe using Whisper\n",
    "    result = model.transcribe(tmp_path)\n",
    "    if birds:\n",
    "        # Find the best matching bird name\n",
    "        bird_name = snap_birds(result['text'].lower(), birds, threshold=70)\n",
    "\n",
    "    # Clean up\n",
    "    os.remove(tmp_path)\n",
    "\n",
    "    return result['text'], bird_name if birds else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bird_name(engine, birds):\n",
    "    bird_recongized = False\n",
    "\n",
    "    while not bird_recongized:\n",
    "        text, bird = get_user_input(4, playback=False, birds=birds)\n",
    "        print(\"Transcribed text:\", text)\n",
    "        print(\"Detected bird:\", bird)\n",
    "        if bird:\n",
    "            bird_recongized = True\n",
    "            return text, bird\n",
    "        else:\n",
    "            engine.say(\"Sorry, I couldn't identify the bird. Please try again.\")\n",
    "            engine.runAndWait()\n",
    "            time.sleep(4)\n",
    "\n",
    "def talk_to_female(engine, list_of_birds):\n",
    "    engine.say(\"Hello lady! Which is your favorite bird?\")\n",
    "    engine.runAndWait()\n",
    "    time.sleep(2)\n",
    "    _, bird = get_bird_name(engine, list_of_birds)\n",
    "    location = \"center\"\n",
    "    color = \"red\"\n",
    "    engine.say(f\"Thank you for letting me know.\")\n",
    "    engine.runAndWait()\n",
    "    engine.say(f'The {bird} is sitting on a {color} ring in the {location} part of the park.')\n",
    "    engine.runAndWait()\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "def talk_to_male(engine, list_of_birds):\n",
    "    engine.say(\"Hello sir! Which is your favorite bird?\")\n",
    "    engine.runAndWait()\n",
    "    time.sleep(2)\n",
    "\n",
    "    bird_confirmed = False\n",
    "    _, pending_bird = get_bird_name(engine, list_of_birds)\n",
    "\n",
    "    while not bird_confirmed:\n",
    "        engine.say(f\"Are you sure that it is {pending_bird}?\")\n",
    "        engine.runAndWait()\n",
    "        time.sleep(1)\n",
    "        text, bird = get_user_input(4, playback=False, birds=list_of_birds)\n",
    "        print(\"Transcribed text:\", text)\n",
    "        print(\"Detected bird:\", bird)\n",
    "        if \"yes\" in text.lower():\n",
    "            bird_confirmed = True\n",
    "            engine.say(f'Thanks for confirming that it is {pending_bird}  .')\n",
    "            engine.runAndWait()\n",
    "            time.sleep(1)\n",
    "        elif bird == pending_bird:\n",
    "            bird_confirmed = True\n",
    "            engine.say(f'Thanks for confirming that it is {pending_bird}  .')\n",
    "            engine.runAndWait()\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            pending_bird = bird\n",
    "            time.sleep(2)\n",
    "\n",
    "\n",
    "    location = \"center\"\n",
    "    color = \"red\"\n",
    "    engine.say(f'The {pending_bird} is sitting on a {color} ring in the {location} part of the park  .')\n",
    "    engine.runAndWait()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = 'F'\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 140)         # words per minute\n",
    "engine.setProperty('volume', 1)       # 0.0‚Äì1.0\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[19].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé§ Recording... Speak now.\n",
      "üì¶ Recording finished. Transcribing...\n",
      "Transcribed text:  Leyson Albatross\n",
      "Detected bird: laysan albatross\n",
      "üé§ Recording... Speak now.\n",
      "üì¶ Recording finished. Transcribing...\n",
      "Transcribed text:  Yes.\n",
      "Detected bird: None\n"
     ]
    }
   ],
   "source": [
    "talk_to_male(engine, list_of_birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé§ Recording... Speak now.\n",
      "üì¶ Recording finished. Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n",
      "ALSA lib pcm.c:8568:(snd_pcm_recover) underrun occurred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] 'vermilion flycatcher' matched 'vermilion flycatcher' with score 100.0\n",
      "You said:   Vermilion Flycatcher\n",
      "Bird species:  vermilion flycatcher\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Save original stderr fd\n",
    "stderr_fileno = sys.stderr.fileno()\n",
    "\n",
    "# Open /dev/null for writing\n",
    "devnull = os.open(os.devnull, os.O_WRONLY)\n",
    "\n",
    "# Duplicate /dev/null fd to stderr fd (2)\n",
    "os.dup2(devnull, stderr_fileno)\n",
    "\n",
    "text, bird = get_user_input(4, playback=True, birds=list_of_birds)\n",
    "print(\"You said: \", text)\n",
    "print(\"Bird species: \", bird)\n",
    "\n",
    "# When done, restore stderr\n",
    "os.dup2(stderr_fileno, stderr_fileno)\n",
    "os.close(devnull)\n",
    "\n",
    "# text, bird = get_user_input(4, playback=True, birds=list_of_birds)\n",
    "# print(\"You said: \", text)\n",
    "# print(\"Bird species: \", bird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['laysan albatross',\n",
       " 'yellow headed blackbird',\n",
       " 'indigo bunting',\n",
       " 'pelagic cormorant',\n",
       " 'american crow',\n",
       " 'yellow billed cuckoo',\n",
       " 'purple finch',\n",
       " 'vermilion flycatcher',\n",
       " 'european goldfinch',\n",
       " 'eared grebe',\n",
       " 'california gull',\n",
       " 'ruby throated hummingbird',\n",
       " 'blue jay',\n",
       " 'pied kingfisher',\n",
       " 'baltimore oriole',\n",
       " 'white pelican',\n",
       " 'horned puffin',\n",
       " 'white necked raven',\n",
       " 'great grey shrike',\n",
       " 'house sparrow',\n",
       " 'cape glossy starling',\n",
       " 'tree swallow',\n",
       " 'common tern',\n",
       " 'red headed woodpecker']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.26086956521739\n",
      "49.090909090909086\n"
     ]
    }
   ],
   "source": [
    "bird_of_interest = \"eared grebe\"\n",
    "print(fuzz.WRatio(\"eared creep.\", bird_of_interest))  # should be 100\n",
    "print(fuzz.WRatio(\"yellow headed blackbird\", bird_of_interest))  # should be < 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eared creep vs eared grebe: 81.81818181818181\n",
      "eared creep vs yellow headed blackbird: 49.090909090909086\n"
     ]
    }
   ],
   "source": [
    "from rapidfuzz import fuzz\n",
    "\n",
    "print(\"eared creep vs eared grebe:\", fuzz.WRatio(\"eared creep\", \"eared grebe\"))\n",
    "print(\"eared creep vs yellow headed blackbird:\", fuzz.WRatio(\"eared creep\", \"yellow headed blackbird\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "['laysan albatross', 'yellow headed blackbird', 'indigo bunting', 'pelagic cormorant', 'american crow']\n"
     ]
    }
   ],
   "source": [
    "print(\"eared grebe\" in list_of_birds)  # should be True\n",
    "print(list_of_birds[:5])               # preview a few bird names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
