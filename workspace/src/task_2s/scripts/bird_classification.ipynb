{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['002.Laysan_Albatross',\n",
       " '012.Yellow_headed_Blackbird',\n",
       " '014.Indigo_Bunting',\n",
       " '025.Pelagic_Cormorant',\n",
       " '029.American_Crow',\n",
       " '033.Yellow_billed_Cuckoo',\n",
       " '035.Purple_Finch',\n",
       " '042.Vermilion_Flycatcher',\n",
       " '048.European_Goldfinch',\n",
       " '050.Eared_Grebe',\n",
       " '059.California_Gull',\n",
       " '068.Ruby_throated_Hummingbird',\n",
       " '073.Blue_Jay',\n",
       " '081.Pied_Kingfisher',\n",
       " '095.Baltimore_Oriole',\n",
       " '101.White_Pelican',\n",
       " '106.Horned_Puffin',\n",
       " '108.White_necked_Raven',\n",
       " '112.Great_Grey_Shrike',\n",
       " '118.House_Sparrow',\n",
       " '134.Cape_Glossy_Starling',\n",
       " '138.Tree_Swallow',\n",
       " '144.Common_Tern',\n",
       " '191.Red_headed_Woodpecker']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PATH_TO_RINS = \"/home/strazi\" # REPLACE WITH YOUR PATH!!!\n",
    "\n",
    "with open(f\"{PATH_TO_RINS}/RINS-kappa/workspace/src/task_2s/data/relevant_species.txt\") as f:\n",
    "    relevant_species = f.read().splitlines()\n",
    "\n",
    "relevant_species = [s.strip() for s in relevant_species if s.strip()]\n",
    "relevant_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    image_id                                         image_name  class_id  \\\n",
      "60        61  002.Laysan_Albatross/Laysan_Albatross_0002_102...         2   \n",
      "61        62  002.Laysan_Albatross/Laysan_Albatross_0003_103...         2   \n",
      "62        63  002.Laysan_Albatross/Laysan_Albatross_0082_524...         2   \n",
      "63        64  002.Laysan_Albatross/Laysan_Albatross_0044_784...         2   \n",
      "64        65  002.Laysan_Albatross/Laysan_Albatross_0070_788...         2   \n",
      "\n",
      "              class_name  is_training_image  bbox_x  bbox_y  bbox_width  \\\n",
      "60  002.Laysan_Albatross                  0   144.0    40.0       333.0   \n",
      "61  002.Laysan_Albatross                  1   202.0    28.0       164.0   \n",
      "62  002.Laysan_Albatross                  0    72.0    68.0       383.0   \n",
      "63  002.Laysan_Albatross                  1    60.0   128.0       438.0   \n",
      "64  002.Laysan_Albatross                  0    32.0    35.0       259.0   \n",
      "\n",
      "    bbox_height                                         image_path  \n",
      "60        165.0  /home/strazi/RINS-kappa/workspace/src/task_2s/...  \n",
      "61        340.0  /home/strazi/RINS-kappa/workspace/src/task_2s/...  \n",
      "62        225.0  /home/strazi/RINS-kappa/workspace/src/task_2s/...  \n",
      "63        106.0  /home/strazi/RINS-kappa/workspace/src/task_2s/...  \n",
      "64        361.0  /home/strazi/RINS-kappa/workspace/src/task_2s/...  \n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "root_dir = f'{PATH_TO_RINS}/RINS-kappa/workspace/src/task_2s/data/CUB_200_2011/CUB_200_2011'\n",
    "images_txt = f'{root_dir}/images.txt'\n",
    "image_class_labels_txt = f'{root_dir}/image_class_labels.txt'\n",
    "classes_txt = f'{root_dir}/classes.txt'\n",
    "train_test_split_txt = f'{root_dir}/train_test_split.txt'\n",
    "bounding_boxes_txt = f'{root_dir}/bounding_boxes.txt'\n",
    "\n",
    "# Load files\n",
    "images_df = pd.read_csv(images_txt, sep=' ', names=['image_id', 'image_name'])\n",
    "labels_df = pd.read_csv(image_class_labels_txt, sep=' ', names=['image_id', 'class_id'])\n",
    "classes_df = pd.read_csv(classes_txt, sep=' ', names=['class_id', 'class_name'])\n",
    "split_df = pd.read_csv(train_test_split_txt, sep=' ', names=['image_id', 'is_training_image'])\n",
    "bboxes_df = pd.read_csv(bounding_boxes_txt, sep=' ', names=['image_id', 'bbox_x', 'bbox_y', 'bbox_width', 'bbox_height'])\n",
    "\n",
    "# Merge all together\n",
    "df = images_df.merge(labels_df, on='image_id') \\\n",
    "              .merge(classes_df, on='class_id') \\\n",
    "              .merge(split_df, on='image_id') \\\n",
    "              .merge(bboxes_df, on='image_id')\n",
    "\n",
    "# Add full image path (optional)\n",
    "df['image_path'] = root_dir + '/images/' + df['image_name']\n",
    "\n",
    "# Filter for relevant species\n",
    "df = df[df['class_name'].isin(relevant_species)]\n",
    "\n",
    "# Show the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 classes\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['class_name'])\n",
    "num_classes = len(le.classes_)\n",
    "print(f'{num_classes} classes')\n",
    "joblib.dump(le, f'{PATH_TO_RINS}/RINS-kappa/workspace/src/task_2s/models/label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['is_training_image'] == 1]\n",
    "test_df = df[df['is_training_image'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_bounding_box(image, bbox):\n",
    "    x, y, w, h = bbox\n",
    "    return image.crop((x, y, x + w, y + h))\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Custom dataset\n",
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'image_path']\n",
    "        label = self.df.loc[idx, 'label']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = BirdDataset(train_df, transform=transform)\n",
    "test_dataset = BirdDataset(test_df, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/strazi/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/strazi/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load pretrained model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Replace the last layer\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.4766, Acc: 38.89%\n",
      "Epoch 2, Loss: 0.7731, Acc: 95.97%\n",
      "Epoch 3, Loss: 0.2773, Acc: 100.00%\n",
      "Epoch 4, Loss: 0.1298, Acc: 100.00%\n",
      "Epoch 5, Loss: 0.0783, Acc: 100.00%\n",
      "Epoch 6, Loss: 0.0502, Acc: 100.00%\n",
      "Epoch 7, Loss: 0.0365, Acc: 100.00%\n",
      "Epoch 8, Loss: 0.0306, Acc: 100.00%\n",
      "Epoch 9, Loss: 0.0241, Acc: 100.00%\n",
      "Epoch 10, Loss: 0.0211, Acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    acc = 100. * correct / total\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Acc: {acc:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 89.50%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100. * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'{PATH_TO_RINS}/RINS-kappa/workspace/src/task_2s/models/bird_species_model.pth'\n",
    "torch.save(model, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
